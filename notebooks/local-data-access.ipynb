{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1784ae2c-c692-4f0d-973d-877aa7f3ffc7",
   "metadata": {},
   "source": [
    "# NCAR Research Data Archive (RDA) Data:  Local Access Options\n",
    "\n",
    "Most, or perhaps all, of data from the RDA is available on NCAR's local file storage systems.\n",
    "\n",
    "For users with access to NCAR compute servers and storage, there are two repositories available:\n",
    "\n",
    "*  Glade, a high-speed file storage system\n",
    "*  Stratus, an object storage system\n",
    "\n",
    "We will go over detailed examples for both cases below, using an example with surface wind data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a4d0f-67c3-4e96-8e7b-2824b3c1fba2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use Case:   Wind Farm Productivity Analysis\n",
    "\n",
    "Suppose someone wants to know the potential amount of electricity that could be generated from a wind farm near Cheyenne, Wyoming.   This means knowing something about the wind speeds in the area, which could vary with the seasons. We might be interested in looking at wind speeds over a single season, or wind speeds over several consecutive years.   In this notebook, we will demonstrate how to do both.\n",
    "\n",
    "The RDA Thredds Data Server has this dataset with surface wind observational data: [ERA5 Reanalysis (0.25 Degree Latitude-Longitude Grid)](https://rda.ucar.edu/datasets/ds633-0/)\n",
    "\n",
    "Among the available data products is a global atmospheric surface analysis in either GRIB or NetCDF format.   \n",
    "\n",
    "Note that we could download the data files directly, but this would be expensive and time-consuming because each data file contains data for the entire globe.  In this example, we care only about one location in Wyoming.  So instead of downloading data for the entire globe, we will use the Xarray and Dask python libraries to load and plot only the data associated with Cheyenne, Wyoming.\n",
    "\n",
    "We will show how to access this dataset, specify which portion of the dataset we wish to extract, and plot the extracted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d83348-0568-4321-a85f-ecf339d82fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d1c8a-3b03-4807-bd24-4b8b469d166c",
   "metadata": {},
   "source": [
    "Here are a few helper functions for data access and wind speed calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ae9b4-0e61-4c34-a86e-6c0b44e39f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filepath_pattern, filename_extension, parallel):\n",
    "    \"\"\" Given a file name pattern specification and a filename extension, return an xarray dataset \n",
    "        containing data from all matching files.   \n",
    "        \n",
    "        `filepath_pattern` must specify a complete path.\n",
    "        \n",
    "        If `parallel = True`, use an existing Dask cluster to open data files.\n",
    "    \"\"\"\n",
    "    full_pattern = filepath_pattern + filename_extension\n",
    "    \n",
    "    # Allow bash-style syntax for file patterns\n",
    "    file_listing = os.popen(f\"/bin/bash -c 'ls {full_pattern}'\").read()\n",
    "    \n",
    "    # Split the output into lines and ignore empty lines\n",
    "    file_list = file_listing.split('\\n')\n",
    "    file_list = [filename for filename in file_list if len(filename) > 0]\n",
    "\n",
    "    # Verify there is at least one matching file\n",
    "    if len(file_list) == 0:\n",
    "        raise ValueError(f'No files match the pattern {full_pattern}')\n",
    "    \n",
    "    ds = xr.open_mfdataset(file_list, parallel=parallel) \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c229e-561c-442f-bd3d-7f467b47ef79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wind_speed(u, v, units=None):\n",
    "    \"\"\"Compute the wind speed from u and v-component numpy arrays.\n",
    "       If units is 'mph', convert from \"meters per second\" to \"miles per hour\".\n",
    "    \"\"\"\n",
    "    speed = np.hypot(u, v)\n",
    "    if units == 'mph':\n",
    "        speed = 2.369 * speed\n",
    "    return speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e6551-8a78-4ab0-9824-d7f4a3579ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_winds(u_values, v_values, time_values):\n",
    "    \"\"\" Compute wind speed values and plot them on a line plot.\n",
    "    \"\"\"\n",
    "    winds = wind_speed(u_values, v_values, units='mph')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.plot(time_values, winds, color='r')\n",
    "    ax.set_title('Hourly Average Wind Speeds for Cheyenne, Wyoming')\n",
    "    ax.set_ylabel('Miles Per Hour')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0548c1a-6b92-480b-b792-a98b4eee8f5b",
   "metadata": {},
   "source": [
    "## Local Glade Access\n",
    "\n",
    "\n",
    "Glade is a multi-petabyte, high availability disk storage system connected to many of NCAR's computing resources.   It is used to store, serve, and process large quantities of numerical data for many users simultaneously.   It provides a UNIX-like interface for accessing files and directories. \n",
    "\n",
    "Most, if not all, of RDA's data assets are located in the directory `/glade/campaign/collections/rda/data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a6597-a4e5-44c6-99f0-5c327737b3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This RDA data directory contains surface analysis data on a 0.25 degree global grid\n",
    "data_dir = '/glade/campaign/collections/rda/data/ds633.0/e5.oper.an.sfc/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e729c454-8d63-4f3d-97e6-134747729712",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Case 1: Relatively few data files and high CPU availability\n",
    "\n",
    "If there are relatively few data files to open, and we are not on a shared system under CPU load, then we do not need Dask parallelism to help speed up the loading process.\n",
    "\n",
    "Here, we construct xarray datasets with the data available for March, April, and May of 2022.   Memory and CPU requirements are not high to obtain this data, but if you are on a heavily used computing system, you may still find it takes a while to load.   If so, see below for how to speed up loading with Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6317e-e4d6-457a-b898-edb06bcb9669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This bash-style pattern will match data for March, April, and May of 2022.\n",
    "year_month_pattern = '2022{03,04,05}/'\n",
    "\n",
    "data_dir = data_dir + year_month_pattern\n",
    "\n",
    "# These filename patterns refer to u- and v-components of winds at 10 meters above the land surface.\n",
    "filename_pattern_u = 'e5.oper.an.sfc.228_131_u10n.ll025sc.*'\n",
    "filename_pattern_v = 'e5.oper.an.sfc.228_132_v10n.ll025sc.*'\n",
    "\n",
    "# Select NetCDF data files\n",
    "filename_extension = '.nc'\n",
    "\n",
    "ds_u = get_dataset(data_dir + filename_pattern_u, filename_extension, parallel=False)\n",
    "ds_v = get_dataset(data_dir + filename_pattern_v, filename_extension, parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198e69e-49f3-4afb-9611-f399a7e62570",
   "metadata": {},
   "source": [
    "The previous step only loaded the structure of the dataset, not the data values.  We can now examine the structure of the dataset, even though the values have not been loaded yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971c0ef-bc2a-4c01-b6a5-90f7fb08aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa678e62-3fa4-401e-b5e2-4bfc211d2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for a specific geographic location (Cheyenne, Wyoming).\n",
    "# Note that dataset longitude values are in the range [0, 360]; click the disk icon to the right of \n",
    "#   \"longitude\" above to verify.\n",
    "# We convert from longitude values provided by Google in the range [-180, 180] using subtraction.\n",
    "\n",
    "# A couple of cities to choose from\n",
    "cheyenne = {'lat': 41.14, 'lon': 360 - 104.82}\n",
    "boulder =  {'lat': 40.01, 'lon': 360 - 105.27}\n",
    "\n",
    "city = cheyenne\n",
    "\n",
    "# Select the nearest grid cell to our lat/lon location.\n",
    "u = ds_u['U10N'].sel(latitude = city['lat'], longitude= city['lon'], method='nearest')\n",
    "v = ds_v['V10N'].sel(latitude = city['lat'], longitude= city['lon'], method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7733b996-0eea-4e7a-83a1-f66ea6c1a378",
   "metadata": {},
   "source": [
    "The entire dataset contains (2208 x 721 x 1440) = 2.29 billion values, but we are only interested in the 2208 time-indexed values associated with Cheyenne, Wyoming.   By subsetting the data, we reduce the required data I/O by a factor of one million.\n",
    "\n",
    "By clicking on the disk-shaped icon to the right of V10N below, we can verify that the entire dataset would require at least 8.54 GiB of memory to load.   We will use subsetting to achieve a drastic reduction in time and memory resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca6af3d-f948-4fda-a159-b20be127ead7",
   "metadata": {},
   "source": [
    "Up to now, only the dataset structure has been loaded into memory.   The next assignment steps pull the subsetted data values into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77776fc-cce2-414e-b898-24c0577cdbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Actually load the data into memory.\n",
    "u_values = u.values\n",
    "v_values = v.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d679328-c48a-4cca-96d7-4e40b203f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plot_winds(u_values, v_values, ds_u.time)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11be79-b587-48b1-a2e2-cc78268412b7",
   "metadata": {},
   "source": [
    "### Case 2: Opening Many Files or Low CPU Availability\n",
    "\n",
    "Using Dask to open and extract datasets is a convenient way to speed up the process.   On shared computing systems with PBS job schedulers such as NCAR's Casper cluster, Dask workers can be allocated using separated, dedicated CPU resources.  \n",
    "\n",
    "In this example, we allocate a Dask cluster with the PBS job scheduler, but it is also possible to allocate Dask clusters using dask_gateway or dask_localcluster, if your system has been configured to allow it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e210bb7-5713-4973-b84f-463e84de1152",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Choose whether to use a PBS Scheduler, Dask Gateway, or LocalCluster to acquire a Dask Cluster\n",
    "\n",
    "If running on a HPC computer with a PBS Scheduler, set to True.  Otherwise, set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4455c4-5bd3-4bec-a39f-001e0aa378a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_PBS_SCHEDULER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84921325-746c-413c-aa48-b0ec2695187f",
   "metadata": {
    "tags": []
   },
   "source": [
    "If running on Jupyter server with Dask Gateway configured, set to True.  Otherwise, set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e1f61-0e9f-47b1-b201-742bd7ecaf16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_DASK_GATEWAY = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04694c6f-df92-46db-9bb2-808612e46fa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Below we specify the maximum size of our Dask cluster.   On a shared computing system, not all Dask workers may be allocated at the same time, but we can specify the upper limit of the number of Dask workers to allocate.  You can think of each worker as having its own \"slice\" of CPU and network resources if the underlying hardware is a node-based architecture, with each node having many CPUs that share a network bus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b607b1-e029-48a3-88bd-e291060e17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the target number of workers for a Dask cluster\n",
    "\n",
    "MAX_WORKERS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2689542-ddcf-45a5-98c1-03b470df218b",
   "metadata": {},
   "source": [
    "## Create and Connect to Dask Distributed Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff9fd5-992b-439e-820b-696b0a60cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gateway_cluster():\n",
    "    \"\"\" Create cluster through dask_gateway\n",
    "    \"\"\"\n",
    "    from dask_gateway import Gateway\n",
    "\n",
    "    gateway = Gateway()\n",
    "    cluster = gateway.new_cluster()\n",
    "    cluster.adapt(minimum=2, maximum=MAX_WORKERS)\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb5ecb8-2785-4e5d-b6b9-c4bbe0fe29c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pbs_cluster():\n",
    "    \"\"\" Create cluster through dask_jobqueue.   \n",
    "    \"\"\"\n",
    "    from dask_jobqueue import PBSCluster\n",
    "    \n",
    "    num_jobs = MAX_WORKERS\n",
    "    walltime = '0:10:00'\n",
    "    memory = '1GB' \n",
    "\n",
    "    cluster = PBSCluster(cores=1, processes=1, walltime=walltime, memory=memory, queue='casper', \n",
    "                         resource_spec=f\"select=1:ncpus=1:mem={memory}\",)\n",
    "    cluster.scale(jobs=num_jobs)\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51fd68-bedb-4700-870a-66a88ee5d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_cluster():\n",
    "    \"\"\" Create cluster using the Jupyter server's resources\n",
    "    \"\"\"\n",
    "    from distributed import LocalCluster\n",
    "    cluster = LocalCluster()    \n",
    "\n",
    "    cluster.scale(MAX_WORKERS)\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b3602-e579-405f-bb56-545bb78d5cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain dask cluster in one of three ways\n",
    "\n",
    "if USE_PBS_SCHEDULER:\n",
    "    cluster = get_pbs_cluster()\n",
    "elif USE_DASK_GATEWAY:\n",
    "    cluster = get_gateway_cluster()\n",
    "else:\n",
    "    cluster = get_local_cluster()\n",
    "\n",
    "# Connect to cluster\n",
    "from distributed import Client\n",
    "client = Client(cluster)\n",
    "\n",
    "# Pause notebook execution until some workers have been allocated.\n",
    "min_workers = 2\n",
    "client.wait_for_workers(min_workers)\n",
    "\n",
    "# Display cluster dashboard URL\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726883a1-8145-4826-a404-2aff483748c7",
   "metadata": {},
   "source": [
    "The following steps are nearly identical to the steps above, but we pull data values for the entire year of 2021 and 2022 using dedicated CPU and memory resources through Dask.  It is enough data that without Dask, you are almost surely going to wait a long time to load all of it.  Note that opening the datasets may be relatively quick, but just before plotting, the data actually gets loaded into memory, and the slowdown can be seen then.\n",
    "\n",
    "Happily, Dask can speed up the work in a way that scales nearly linearly with the number of workers in the Dask cluster.  In other words, if your cluster has 5 workers, the data should load 5 times faster than when not using Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc5d4c-26c6-432c-9cdf-d07fff5b7542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This subdirectory contains surface analysis data on a 0.25 degree global grid\n",
    "data_dir = '/glade/campaign/collections/rda/data/ds633.0/e5.oper.an.sfc/'\n",
    "\n",
    "# This bash-style pattern will match data for 2021 and 2022.\n",
    "year_month_pattern = '202{1,2}*/'\n",
    "\n",
    "data_dir = data_dir + year_month_pattern\n",
    "\n",
    "# These filename patterns refer to u- and v-components of winds at 10 meters above the land surface.\n",
    "filename_pattern_u = 'e5.oper.an.sfc.228_131_u10n.ll025sc.*'\n",
    "filename_pattern_v = 'e5.oper.an.sfc.228_132_v10n.ll025sc.*'\n",
    "\n",
    "# Select NetCDF data files\n",
    "filename_extension = '.nc'\n",
    "\n",
    "ds_u = get_dataset(data_dir + filename_pattern_u, filename_extension, parallel=True)\n",
    "ds_v = get_dataset(data_dir + filename_pattern_v, filename_extension, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82807b1-cfb4-42f8-8388-f338bb1eb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see the structure of the dataset, even though the values have not been loaded yet.\n",
    "\n",
    "ds_v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02efbf71-aad1-4f6b-bb78-00281de3b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for a specific geographic location (Cheyenne, Wyoming).\n",
    "# Note that dataset longitude values are in the range [0, 360]; click the disk icon to the right of \n",
    "#   \"longitude\" above to verify.\n",
    "# We convert from longitude values provided by Google in the range [-180, 180] using subtraction.\n",
    "\n",
    "cheyenne = {'lat': 41.14, 'lon': 360 - 104.82}\n",
    "boulder =  {'lat': 40.01, 'lon': 360 - 105.27}\n",
    "\n",
    "city = cheyenne\n",
    "\n",
    "# Select the nearest grid cell to our lat/lon location.\n",
    "u = ds_u['U10N'].sel(latitude = city['lat'], longitude= city['lon'], method='nearest')\n",
    "v = ds_v['V10N'].sel(latitude = city['lat'], longitude= city['lon'], method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b424d-d250-4dbb-8edd-bce7325f632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Actually load the data into memory.\n",
    "u_values = u.values\n",
    "v_values = v.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9f0ab7-f532-4161-bd13-328053a88c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plot_winds(u_values, v_values, ds_u.time)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f06a45-6d57-4c9f-9c6d-9b281b4021d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e587799c-0677-4155-9f0c-f475fb4f9395",
   "metadata": {},
   "source": [
    "## Stratus Object Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebf897-a113-408b-9e01-91c2a1082386",
   "metadata": {},
   "source": [
    "Question:  are there RDA datasets on Stratus that are not on Glade?   \n",
    "\n",
    "In other words, can we highlight RDA use cases specific to Stratus?   Or follow the above use case if ds633.0 is also on Stratus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dca132-ac7b-4a57-9c94-a60420294a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1dc380-0f3c-4815-b8fa-72cd1f82ca1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30dd26-cc87-401f-946d-22b59c476358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d010961-b68c-4513-9737-05880cfd10c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78428321-4f2f-44c3-bd53-859d828154cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b0486-c62c-4de5-996b-1438f38d793c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166ac1a-2301-4d8b-9595-2a6b97b249e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-explore-siphon]",
   "language": "python",
   "name": "conda-env-miniconda3-explore-siphon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
