{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Diagnostic Plots for NA-CORDEX Zarr Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import intake\n",
    "import ast\n",
    "import dask_jobqueue\n",
    "import matplotlib.pyplot as plt\n",
    "#import fsspec\n",
    "#import s3fs\n",
    "\n",
    "from dask_jobqueue import PBSCluster\n",
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Connect to a Dask Distributed Cluster\n",
    "\n",
    "Run the cell below if the notebook is running on a NCAR supercomputer.\n",
    "If the notebook is running on a different parallel computing environment, you will need \n",
    "to replace the usage of `NCARCluster` with a similar object from `dask_jobqueue` or `dask_gateway`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_jobs = 20\n",
    "walltime = '0:20:00'\n",
    "memory='10GB' \n",
    "\n",
    "cluster = PBSCluster(cores=1, processes=1, walltime=walltime, memory=memory, queue='casper', \n",
    "                     resource_spec='select=1:ncpus=1:mem=10GB',)\n",
    "cluster.scale(jobs=num_jobs)\n",
    "\n",
    "\n",
    "from distributed import Client\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ Link to Dask dashboard will appear above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Obtain Data Using an Intake Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose Cloud Storage (AWS or NCAR Cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True,  use NCAR Cloud Storage.   \n",
    "# If False, use AWS  Cloud Storage.\n",
    "\n",
    "USE_NCAR_CLOUD = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Intake Catalog URL and Storage Access Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_NCAR_CLOUD:\n",
    "    catalog_url = \"https://stratus.ucar.edu/ncar-na-cordex/catalogs/aws-na-cordex.json\"\n",
    "    storage_options={\"anon\": True, 'client_kwargs':{\"endpoint_url\":\"https://stratus.ucar.edu/\"}}\n",
    "                     \n",
    "else:\n",
    "    catalog_url = \"https://ncar-na-cordex.s3-us-west-2.amazonaws.com/catalogs/aws-na-cordex.json\"\n",
    "    storage_options={\"anon\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open catalog and produce a content summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the catalog interpret the \"na-cordex-models\" column as a list of values, as opposed to single values.\n",
    "col = intake.open_esm_datastore(catalog_url, read_csv_kwargs={\"converters\": {\"na-cordex-models\": ast.literal_eval}},)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few lines of the catalog\n",
    "col.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a catalog content summary.\n",
    "import pprint\n",
    "\n",
    "uniques = col.unique()\n",
    "\n",
    "columns = [\"variable\", \"scenario\", \"grid\", \"na-cordex-models\", \"bias_correction\"]\n",
    "for column in columns:\n",
    "    print(f'{column}: {uniques[column]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data into xarray using the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_var = 'tmax'\n",
    "\n",
    "col_subset = col.search(\n",
    "    variable=data_var,\n",
    "    grid=\"NAM-44i\",\n",
    "    scenario=\"eval\",\n",
    "    bias_correction=\"raw\",\n",
    ")\n",
    "\n",
    "col_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catalog entries for subset into a dictionary of xarray datasets, and open the first one.\n",
    "dsets = col_subset.to_dataset_dict(\n",
    "    xarray_open_kwargs={\"consolidated\": True}, storage_options=storage_options\n",
    ")\n",
    "print(f\"\\nDataset dictionary keys:\\n {dsets.keys()}\")\n",
    "\n",
    "# Load the first dataset and display a summary.\n",
    "dataset_key = list(dsets.keys())[0]\n",
    "store_name = dataset_key + \".zarr\"\n",
    "\n",
    "ds = dsets[dataset_key]\n",
    "ds\n",
    "\n",
    "# Note that the summary includes a 'member_id' coordinate, which is a renaming of the \n",
    "# 'na-cordex-models' column in the catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function to Create a Single Map Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMap(ax, map_slice, date_object=None, member_id=None):\n",
    "    \"\"\"Create a map plot on the given axes, with min/max as text\"\"\"\n",
    "\n",
    "    ax.imshow(map_slice, origin='lower')\n",
    "\n",
    "    minval = map_slice.min(dim = ['lat', 'lon'])\n",
    "    maxval = map_slice.max(dim = ['lat', 'lon'])\n",
    "\n",
    "    # Format values to have at least 4 digits of precision.\n",
    "    ax.text(0.01, 0.03, \"Min: %3g\" % minval, transform=ax.transAxes, fontsize=12)\n",
    "    ax.text(0.99, 0.03, \"Max: %3g\" % maxval, transform=ax.transAxes, fontsize=12, horizontalalignment='right')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    if date_object:\n",
    "        ax.set_title(date_object.values.astype(str)[:10], fontsize=12)\n",
    "        \n",
    "    if member_id:\n",
    "        ax.set_ylabel(member_id, fontsize=12)\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function for Finding Dates with Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidDateIndexes(member_slice):\n",
    "    \"\"\"Search for the first and last dates with finite values.\"\"\"\n",
    "    min_values = member_slice.min(dim = ['lat', 'lon'])\n",
    "    is_finite = np.isfinite(min_values)\n",
    "    finite_indexes = np.where(is_finite)\n",
    "\n",
    "    start_index = finite_indexes[0][0]\n",
    "    end_index = finite_indexes[0][-1]\n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Producing Maps of First, Middle, and Final Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_mid_last(ds, data_var, store_name):\n",
    "    \"\"\"Plot the first, middle, and final time steps for several climate runs.\"\"\"\n",
    "    num_members_to_plot = 4\n",
    "    member_names = ds.coords['member_id'].values[0:num_members_to_plot]\n",
    "    \n",
    "    figWidth = 18 \n",
    "    figHeight = 12 \n",
    "    numPlotColumns = 3\n",
    "    fig, axs = plt.subplots(num_members_to_plot, numPlotColumns, figsize=(figWidth, figHeight), constrained_layout=True)\n",
    "\n",
    "    for index in np.arange(num_members_to_plot):\n",
    "        mem_id = member_names[index]\n",
    "        data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "           \n",
    "        start_index, end_index = getValidDateIndexes(data_slice)\n",
    "        midDateIndex = np.floor(len(ds.time) / 2).astype(int)\n",
    "\n",
    "        startDate = ds.time[start_index]\n",
    "        first_step = data_slice.sel(time=startDate) \n",
    "        ax = axs[index, 0]\n",
    "        plotMap(ax, first_step, startDate, mem_id)\n",
    "\n",
    "        midDate = ds.time[midDateIndex]\n",
    "        mid_step = data_slice.sel(time=midDate)   \n",
    "        ax = axs[index, 1]\n",
    "        plotMap(ax, mid_step, midDate)\n",
    "\n",
    "        endDate = ds.time[end_index]\n",
    "        last_step = data_slice.sel(time=endDate)            \n",
    "        ax = axs[index, 2]\n",
    "        plotMap(ax, last_step, endDate)\n",
    "        \n",
    "        plt.suptitle(f'First, Middle, and Last Timesteps for Selected Runs in \"{store_name}\"', fontsize=20)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Producing Statistical Map Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stat_maps(ds, data_var, store_name):\n",
    "    \"\"\"Plot the mean, min, max, and standard deviation values for several climate runs, aggregated over time.\"\"\"\n",
    "    \n",
    "    num_members_to_plot = 4\n",
    "    member_names = ds.coords['member_id'].values[0:num_members_to_plot]\n",
    "\n",
    "    figWidth = 25 \n",
    "    figHeight = 12 \n",
    "    numPlotColumns = 4\n",
    "    \n",
    "    fig, axs = plt.subplots(num_members_to_plot, numPlotColumns, figsize=(figWidth, figHeight), constrained_layout=True)\n",
    "\n",
    "    for index in np.arange(num_members_to_plot):\n",
    "        mem_id = member_names[index]\n",
    "        data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "\n",
    "        data_agg = data_slice.min(dim='time')\n",
    "        plotMap(axs[index, 0], data_agg, member_id=mem_id)\n",
    "\n",
    "        data_agg = data_slice.max(dim='time')\n",
    "        plotMap(axs[index, 1], data_agg)\n",
    "\n",
    "        data_agg = data_slice.mean(dim='time')\n",
    "        plotMap(axs[index, 2], data_agg)\n",
    "\n",
    "        data_agg = data_slice.std(dim='time')\n",
    "        plotMap(axs[index, 3], data_agg)\n",
    "\n",
    "    axs[0, 0].set_title(f'min({data_var})', fontsize=15)\n",
    "    axs[0, 1].set_title(f'max({data_var})', fontsize=15)\n",
    "    axs[0, 2].set_title(f'mean({data_var})', fontsize=15)\n",
    "    axs[0, 3].set_title(f'std({data_var})', fontsize=15)\n",
    "\n",
    "    plt.suptitle(f'Spatial Statistics for Selected Runs in \"{store_name}\"', fontsize=20)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Producing Time Series Plots\n",
    "Also show which dates have no available data values, as a rug plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(ds, data_var, store_name):\n",
    "    \"\"\"Plot the mean, min, max, and standard deviation values for several climate runs, \n",
    "       aggregated over lat/lon dimensions.\"\"\"\n",
    "\n",
    "    num_members_to_plot = 4\n",
    "    member_names = ds.coords['member_id'].values[0:num_members_to_plot]\n",
    "\n",
    "    figWidth = 25 \n",
    "    figHeight = 20\n",
    "    linewidth = 0.5\n",
    "\n",
    "    numPlotColumns = 1\n",
    "    fig, axs = plt.subplots(num_members_to_plot, numPlotColumns, figsize=(figWidth, figHeight))\n",
    "        \n",
    "    for index in np.arange(num_members_to_plot):\n",
    "        mem_id = member_names[index]\n",
    "        data_slice = ds[data_var].sel(member_id=mem_id)\n",
    "        unit_string = ds[data_var].attrs['units']\n",
    "        \n",
    "        min_vals = data_slice.min(dim = ['lat', 'lon'])\n",
    "        max_vals = data_slice.max(dim = ['lat', 'lon'])\n",
    "        mean_vals = data_slice.mean(dim = ['lat', 'lon'])\n",
    "        std_vals = data_slice.std(dim = ['lat', 'lon'])\n",
    "\n",
    "        #missing_indexes = np.isnan(min_vals)\n",
    "        missing_indexes = np.isnan(min_vals).compute()\n",
    "        missing_times = ds.time[missing_indexes]\n",
    "\n",
    "            \n",
    "        axs[index].plot(ds.time, max_vals, linewidth=linewidth, label='max', color='red')\n",
    "        axs[index].plot(ds.time, mean_vals, linewidth=linewidth, label='mean', color='black')\n",
    "        axs[index].fill_between(ds.time, (mean_vals - std_vals), (mean_vals + std_vals), \n",
    "                                         color='grey', linewidth=0, label='std', alpha=0.5)\n",
    "        axs[index].plot(ds.time, min_vals, linewidth=linewidth, label='min', color='blue')\n",
    "            \n",
    "        ymin, ymax = axs[index].get_ylim()\n",
    "        rug_y = ymin + 0.01*(ymax-ymin)\n",
    "        axs[index].plot(missing_times, [rug_y]*len(missing_times), '|', color='m', label='missing')\n",
    "        axs[index].set_title(mem_id, fontsize=20)\n",
    "        axs[index].legend(loc='upper right')\n",
    "        axs[index].set_ylabel(unit_string)\n",
    "\n",
    "    plt.tight_layout(pad=10.2, w_pad=3.5, h_pad=3.5)\n",
    "    plt.suptitle(f'Temporal Statistics for Selected Runs in \"{store_name}\"', fontsize=20)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce Diagnostic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot First, Middle, and Final Timesteps for Several Output Runs (less compute intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Plot using the Zarr Store obtained from an earlier step in the notebook.\n",
    "figure = plot_first_mid_last(ds, data_var, store_name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: save figure to a PNG file\n",
    "\n",
    "Change the value of SAVE_PLOT to True to produce a PNG file of the plot.   The file will be saved in the same folder as this notebook.\n",
    "\n",
    "Then use Jupyter's file browser to locate the file and right-click the file to download it.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PLOT = False\n",
    "if SAVE_PLOT:\n",
    "    plotfile = f'./{dataset_key}_FML.png'\n",
    "    figure.savefig(plotfile, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Statistical Map Plots for Several Output Runs (more compute intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Plot using the Zarr Store obtained from an earlier step in the notebook.\n",
    "figure = plot_stat_maps(ds, data_var, store_name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: save figure to a PNG file\n",
    "\n",
    "Change the value of SAVE_PLOT to True to produce a PNG file of the plot.   The file will be saved in the same folder as this notebook.\n",
    "\n",
    "Then use Jupyter's file browser to locate the file and right-click the file to download it.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PLOT = False\n",
    "if SAVE_PLOT:\n",
    "    plotfile = f'./{dataset_key}_MAPS.png'\n",
    "    figure.savefig(plotfile, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Time Series for Several Output Runs (more compute intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Plot using the Zarr Store obtained from an earlier step in the notebook.\n",
    "figure = plot_timeseries(ds, data_var, store_name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: save figure to a PNG file\n",
    "\n",
    "Change the value of SAVE_PLOT to True to produce a PNG file of the plot.   The file will be saved in the same folder as this notebook.\n",
    "\n",
    "Then use Jupyter's file browser to locate the file and right-click the file to download it.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PLOT = False\n",
    "if SAVE_PLOT:\n",
    "    plotfile = f'./{dataset_key}_TS.png'\n",
    "    figure.savefig(plotfile, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-na-cordex-cloud-project]",
   "language": "python",
   "name": "conda-env-miniconda3-na-cordex-cloud-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
